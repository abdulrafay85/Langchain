{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser, CommaSeparatedListOutputParser, PydanticOutputParser\n",
    "from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Parser\n",
    "   LangChain mein output parser ka istemal aapko LLM se milne wale output ko desired format mein convert karne ke liye hota hai."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CommaSeparatedListOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.chains import LLMChain\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "os.environ[\"GEMINI_API_KEY\"] = gemini_api_key\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    api_key=gemini_api_key,  # Ensure this variable is defined correctly\n",
    "    temperature=0.2,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "# Create the prompt template correctly\n",
    "prompt = PromptTemplate(\n",
    "    template=\"List five {subject}.\\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "\n",
    "# Use LLMChain to create the chain\n",
    "chain = LLMChain(\n",
    "    prompt=prompt,\n",
    "    llm=llm,\n",
    "    output_parser=output_parser\n",
    ")\n",
    "\n",
    "# Invoke the chain\n",
    "res = chain.invoke({\"subject\" : \"ice cream flavors\"})\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DatetimeOutputParser\n",
    "\n",
    "#### 1. `.get_format_instructions()`\n",
    "- **Kya Karta Hai**: Yeh method aapko batata hai ke output ka format kya hoga. \n",
    "- **Example**: Agar aapne specify kiya hai ke aapko date chahiye is format mein: \"Fri 10/02/2024\", toh jab aap `.get_format_instructions()` call karenge, yeh yeh format aapko dikhayega.\n",
    "\n",
    "#### 2. `.parse()`\n",
    "- **Kya Karta Hai**: Yeh method model se mila output ko check karta hai aur usay format karta hai.\n",
    "- **Example**: Agar model se output aata hai \"2024-02-10 00:00:00\" aur aap chahte hain ke yeh \"Fri 10/02/2024\" ban jaaye, toh aap is output ko `.parse()` method mein dete hain. Yeh method yeh check karega aur agar output valid nahi hai, toh error throw karega.\n",
    "\n",
    "#### Summary:\n",
    "- **`.get_format_instructions()`**: Aapko format ka idea deta hai.\n",
    "- **`.parse()`**: Model ka output le kar use correct format mein badalta hai.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Content :\t 1947-08-14T00:00:00.000000Z \n",
      "\n",
      "Response Content Parse :\t 1947-08-14 00:00:00\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser, CommaSeparatedListOutputParser, PydanticOutputParser\n",
    "from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Load the API key from .env file\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "os.environ[\"GEMINI_API_KEY\"] = gemini_api_key\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    api_key=gemini_api_key,  # Corrected the variable usage\n",
    "    temperature=0.2,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# # Example 1\n",
    "date_time_parser = DatetimeOutputParser(Hformat=\"%a %d/%m/%Y\")\n",
    "# print(date_time_parser.get_format_instructions())\n",
    "\n",
    "human_template = \"{request}\\n{format_instruction}\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    HumanMessagePromptTemplate.from_template(human_template)\n",
    " ])\n",
    "\n",
    "# print(prompt)\n",
    "\n",
    "formated_prompt = prompt.format_messages(\n",
    "    request=\"When did Pakistan gain independence?\",\n",
    "    format_instruction=date_time_parser.get_format_instructions(),\n",
    ")\n",
    "\n",
    "res = llm.invoke(formated_prompt)\n",
    "# Example 1\n",
    "print(\"Response Content :\\t\", res.content)\n",
    "\n",
    "# Example 2\n",
    "print(\"Response Content Parse :\\t\", date_time_parser.parse(\n",
    "    res.content\n",
    "))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Kya Ho Raha Hai:\n",
    "\n",
    "1. **Parser Setup**: \n",
    "   - Aap `JsonOutputParser` ka istemal kar rahe hain. Yeh ek tool hai jo model se milne wale jawab ko JSON format mein badalta hai.\n",
    "\n",
    "2. **Pydantic Object**:\n",
    "   - `Joke` ek class hai jo batati hai ke aapko data kaise chahiye. Jaise, `Joke` class mein ho sakta hai ke \"joke\" aur \"punchline\" ki fields hon.\n",
    "\n",
    "### Instructions Ko Inject Karna:\n",
    "- Jab aap `pydantic_object=Joke` dete hain, toh aap parser ko keh rahe hain ke:\n",
    "  - \"Mujhe yeh output chahiye, jo `Joke` class ke format mein ho.\"\n",
    "\n",
    "### Iska Faida:\n",
    "- Yeh ensure karta hai ke jab model se jawab aaye, toh woh us structure ke mutabiq ho. Agar nahi hua, toh parser error dega.\n",
    "\n",
    "### Example:\n",
    "- Sochiye ke aapne `Joke` class mein yeh define kiya hai:\n",
    "  ```python\n",
    "  class Joke(BaseModel):\n",
    "      joke: str\n",
    "      punchline: str\n",
    "  ```\n",
    "\n",
    "- Agar model se aisa jawab aaye:\n",
    "  ```json\n",
    "  {\n",
    "      \"joke\": \"Why did the chicken cross the road?\",\n",
    "      \"punchline\": \"To get to the other side!\"\n",
    "  }\n",
    "  ```\n",
    "- Toh `JsonOutputParser` yeh check karega ke yeh structure sahi hai ya nahi. Agar sahi hai, toh aapko yeh data mil jayega. Agar nahi, toh error aayega.\n",
    "\n",
    "### Summary:\n",
    "- Aap parser ko `Joke` class dete hain taake yeh ensure ho ke output us format mein ho jo aap chahte hain. Is tarah aapko sahi aur structured data milta hai.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of  <class 'langchain_core.output_parsers.json.JsonOutputParser'>\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain.chains import LLMChain\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from the environment\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "os.environ[\"GEMINI_API_KEY\"] = gemini_api_key\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    api_key=gemini_api_key,\n",
    "    temperature=0.2,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Define the data structure (Joke model)\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "# Set up the JSON output parser\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "\n",
    "\n",
    "# # Create the prompt template\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# # Create the LLM chain\n",
    "# chain = LLMChain(\n",
    "#     prompt=prompt,\n",
    "#     llm=llm,  # Pass the LLM model correctly here\n",
    "#     output_parser=parser  # Correctly set the output parser here\n",
    "# )\n",
    "\n",
    "# # Query to get the joke\n",
    "# joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# # Invoke the chain with the query\n",
    "# res = chain.invoke({\"query\": joke_query})\n",
    "\n",
    "# # Print the result\n",
    "# print(res)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
